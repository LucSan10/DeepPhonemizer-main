{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob(\"dp/notebooks/lexicons/*\")\n",
    "allFiles.sort()\n",
    "allDF = []\n",
    "\n",
    "for f in allFiles:\n",
    "    filename = f.split(\"/\")[3][:-4]\n",
    "    df = pd.read_csv(f, dtype=str,\n",
    "        encoding='utf-8', sep='\\t',\n",
    "        names=['grapheme', 'phoneme'])\n",
    "    df.insert(2, 'filename', filename)\n",
    "    allDF.append(df)\n",
    "\n",
    "df = pd.concat(allDF, ignore_index=True)\n",
    "df.insert(0, 'lang', 'pt_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grapheme'] = df['grapheme'].map(str)\n",
    "df['phoneme'] = df['phoneme'].map(str)\n",
    "\n",
    "graphemes = ''.join(sorted(list(set(df['grapheme'].sum()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' !()+,-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzªÀÁÂÉÊÍÓÚàáâãçéêíóôõöúûüý'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gWords'] = df['grapheme'].str.count(' ') + 1\n",
    "df['pWords'] = df['phoneme'].str.count(' ') + 1\n",
    "df['grapheme'] = df['grapheme'].str.split(' ')\n",
    "df['phoneme'] = df['phoneme'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.groupby('filename', as_index=False)\n",
    "    .apply(lambda x: x.reset_index(drop=True)).reset_index().drop('level_0', axis=1))\n",
    "df.level_1 = df.level_1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gWords > df.pWords].apply(lambda x:\n",
    "    x.phoneme.extend([''] * (x.gWords - x.pWords)), axis=1)\n",
    "df[df.pWords > df.gWords].apply(lambda x:\n",
    "    x.grapheme.extend([''] * (x.pWords - x.gWords)), axis=1)\n",
    "dfWords = (df.apply(pd.Series.explode)\n",
    "    .drop(['lang', 'gWords', 'pWords'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9f86a40b9686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mallDFFixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfFixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdfFixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallDFFixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdfFixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pt_br'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "allFilesFixed = glob.glob(\"dp/notebooks/lexicons_fixed/*\")\n",
    "allFilesFixed.sort()\n",
    "allDFFixed = []\n",
    "\n",
    "for f in allFilesFixed:\n",
    "    filename = f.split(\"/\")[3][:-4]\n",
    "    dfFixed = pd.read_csv(f, dtype=str,\n",
    "        encoding='utf-8', sep='\\t',\n",
    "        names=['grapheme', 'phoneme'])\n",
    "    dfFixed.insert(2, 'filename', filename)\n",
    "    allDFFixed.append(dfFixed)\n",
    "\n",
    "dfFixed = pd.concat(allDFFixed, ignore_index=True)\n",
    "dfFixed.insert(0, 'lang', 'pt_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed['gWords'] = dfFixed['grapheme'].str.count(' ') + 1\n",
    "dfFixed['pWords'] = dfFixed['phoneme'].str.count(' ') + 1\n",
    "dfFixed['grapheme'] = dfFixed['grapheme'].str.split(' ')\n",
    "dfFixed['phoneme'] = dfFixed['phoneme'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed = (dfFixed.groupby('filename', as_index=False)\n",
    "    .apply(lambda x: x.reset_index(drop=True)).reset_index().drop('level_0', axis=1))\n",
    "dfFixed.level_1 = dfFixed.level_1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed[dfFixed.gWords > dfFixed.pWords].apply(lambda x:\n",
    "    x.phoneme.extend([''] * (x.gWords - x.pWords)), axis=1)\n",
    "dfFixed[dfFixed.pWords > dfFixed.gWords].apply(lambda x:\n",
    "    x.grapheme.extend([''] * (x.pWords - x.gWords)), axis=1)\n",
    "dfFixedWords = (dfFixed.apply(pd.Series.explode)\n",
    "    .drop(['lang', 'gWords', 'pWords'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = dfWords['phoneme']\n",
    "phonemesFixed = dfFixedWords['phoneme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24653"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(phonemes != phonemesFixed).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon = dfWords[phonemesFixed != phonemes][['filename', 'level_1', 'grapheme', 'phoneme']]\n",
    "phonFixed = dfFixedWords[phonemes != phonemesFixed][['filename', 'level_1', 'grapheme', 'phoneme']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon.to_csv('phon.txt', index=False)\n",
    "phonFixed.to_csv('phonFixed.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWords.drop_duplicates(subset=['grapheme', 'phoneme']).to_csv('words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixedWords.drop_duplicates(subset=['grapheme', 'phoneme']).to_csv('words_fixed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grapheme'] = df['grapheme'].map(str)\n",
    "df['phoneme'] = df['phoneme'].map(str)\n",
    "\n",
    "graphemes = ''.join(sorted(list(set(df['grapheme'].sum()))))\n",
    "\n",
    "phonemes = (\n",
    "    df['phoneme'].str.split(\"\\\\\")\n",
    "        .explode().drop_duplicates()\n",
    "        .sort_values().reset_index(drop=True)\n",
    "        .values.tolist()\n",
    ")\n",
    "\n",
    "phonemes.append('~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' ',\n",
       " \" '\",\n",
       " \"'\",\n",
       " '.',\n",
       " 'E',\n",
       " 'J',\n",
       " 'L',\n",
       " 'O',\n",
       " 'R',\n",
       " 'S',\n",
       " 'X',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'a~',\n",
       " 'b',\n",
       " 'd',\n",
       " 'dZ',\n",
       " 'e',\n",
       " 'ej',\n",
       " 'e~',\n",
       " 'e~j~',\n",
       " 'f',\n",
       " 'g',\n",
       " 'i',\n",
       " 'i~',\n",
       " 'j',\n",
       " 'js',\n",
       " 'j~',\n",
       " 'j~s',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'ow',\n",
       " 'o~',\n",
       " 'p',\n",
       " 'pau',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'tS',\n",
       " 'u',\n",
       " 'u~',\n",
       " 'v',\n",
       " 'w',\n",
       " 'w~',\n",
       " 'z',\n",
       " '~']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFilesFixed = glob.glob(\"dp/notebooks/lexicons_fixed/*\")\n",
    "allFilesFixed.sort()\n",
    "allDFFixed = []\n",
    "\n",
    "for f in allFilesFixed:\n",
    "    filename = f.split(\"/\")[3][:-4]\n",
    "    dfFixed = pd.read_csv(f, dtype=str,\n",
    "        encoding='utf-8', sep='\\t',\n",
    "        names=['grapheme', 'phoneme'])\n",
    "    dfFixed.insert(2, 'filename', filename)\n",
    "    allDFFixed.append(dfFixed)\n",
    "\n",
    "dfFixed = pd.concat(allDFFixed, ignore_index=True)\n",
    "dfFixed['phoneme'] = dfFixed['phoneme'].str.replace('\\\\\\\\pau\\\\\\\\',\",\")\n",
    "dfFixed['phoneme'] = dfFixed['phoneme'].str.replace('\\\\','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed.to_csv('lex.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(target, predicted):\n",
    "    d = np.zeros((len(target) + 1) * (len(predicted) + 1), dtype=np.uint8)\n",
    "    d = d.reshape((len(target) + 1, len(predicted) + 1))\n",
    "    for i in range(len(target) + 1):\n",
    "        for j in range(len(predicted) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    for i in range(1, len(target) + 1):\n",
    "        for j in range(1, len(predicted) + 1):\n",
    "            if target[i - 1] == predicted[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    return d[len(target)][len(predicted)], len(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"e~'ta~w~, ki des'kuw.pa me'LOX 'pa.ra fi.kaR.muZu~'tus\"\n",
    "predicted = \"e~'ta~w~pau ki dZi ki 'pla 'mO.La pra'zi u~ 'muj~\"\n",
    "\n",
    "res = levenshtein(target=target, predicted=predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 54)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"'\", 'm', 'a', '.', 't', 'a', ' ', \"'\", 's', ' ', \"'\", 's', ' ', \"'\", ...]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cde60fc070cc7e7c1fe92306444b0b222b6cd64a006490f96de528ff53cd4f57"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
