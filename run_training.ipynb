{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob(\"dp/notebooks/lexicons/*\")\n",
    "allFiles.sort()\n",
    "allDF = []\n",
    "\n",
    "for f in allFiles:\n",
    "    filename = f.split(\"/\")[3][:-4]\n",
    "    df = pd.read_csv(f, dtype=str, engine='python',\n",
    "        encoding='utf-8', sep='\\t',\n",
    "        names=['grapheme', 'phoneme'])\n",
    "    df.insert(2, 'filename', filename)\n",
    "    allDF.append(df)\n",
    "\n",
    "df = pd.concat(allDF, ignore_index=True)\n",
    "df.insert(0, 'lang', 'pt_br')\n",
    "df['phoneme'] = df['phoneme'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grapheme'] = df['grapheme'].map(str)\n",
    "df['phoneme'] = df['phoneme'].map(str)\n",
    "\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"\\\\\\\\pau\\\\\\\\\", '\\\\\\\\,\\\\\\\\')\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"a~\", \"ã\")\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"e~\", \"ẽ\")\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"i~\", \"ĩ\")\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"o~\", \"õ\")\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"u~\", \"ũ\")\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"w~\", \"w̃\")\n",
    "df['phoneme'] = df['phoneme'].str.replace(\"j~\", \"j̃\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphemes = ''.join(sorted(list(set(df['grapheme'].sum()))))\n",
    "\n",
    "phonemes = pd.DataFrame(\n",
    "    df['phoneme'].str.split(\"\\\\\")\n",
    "        .explode().drop_duplicates()\n",
    "        .sort_values().reset_index(drop=True)\n",
    "        .values.tolist(), columns=['phon']\n",
    ")\n",
    "\n",
    "phonemes['len'] = phonemes['phon'].str.len()\n",
    "phonemes['upper'] = phonemes['phon'].str.isupper()\n",
    "phonemes = phonemes.sort_values(by=['len', 'upper', 'phon'], ascending=False)['phon'].values.tolist()\n",
    "\n",
    "phonemes.append(\"~\")\n",
    "phonemes.remove(\" '\")\n",
    "phonemes.remove(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['phoneme'] = df['phoneme'].str.replace('\\\\', '')\n",
    "df['gsize'] = df['grapheme'].apply(lambda x : len(x))\n",
    "df['psize'] = df['phoneme'].apply(lambda x : len(x))\n",
    "df = df[df['psize'] <= 100]\n",
    "phonemes.sort(key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gWords'] = df['grapheme'].str.count(' ') + 1\n",
    "df['pWords'] = df['phoneme'].str.count(' ') + 1\n",
    "df['grapheme'] = df['grapheme'].str.split(' ')\n",
    "df['phoneme'] = df['phoneme'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (df.groupby('filename', as_index=False)\n",
    "    .apply(lambda x: x.reset_index(drop=True)).reset_index().drop('level_0', axis=1))\n",
    "df.level_1 = df.level_1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.gWords > df.pWords].apply(lambda x:\n",
    "    x.phoneme.extend([''] * (x.gWords - x.pWords)), axis=1)\n",
    "df[df.pWords > df.gWords].apply(lambda x:\n",
    "    x.grapheme.extend([''] * (x.pWords - x.gWords)), axis=1)\n",
    "dfWords = (df.apply(pd.Series.explode)\n",
    "    .drop(['lang', 'gWords', 'pWords'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9f86a40b9686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mallDFFixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfFixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdfFixed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallDFFixed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mdfFixed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pt_br'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch/lib/python3.6/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "allFilesFixed = glob.glob(\"dp/notebooks/lexicons_fixed/*\")\n",
    "allFilesFixed.sort()\n",
    "allDFFixed = []\n",
    "\n",
    "for f in allFilesFixed:\n",
    "    filename = f.split(\"/\")[3][:-4]\n",
    "    dfFixed = pd.read_csv(f, dtype=str,\n",
    "        encoding='utf-8', sep='\\\\t',\n",
    "        names=['grapheme', 'phoneme'])\n",
    "    dfFixed.insert(2, 'filename', filename)\n",
    "    allDFFixed.append(dfFixed)\n",
    "\n",
    "dfFixed = pd.concat(allDFFixed, ignore_index=True)\n",
    "dfFixed.insert(0, 'lang', 'pt_br')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed['gWords'] = dfFixed['grapheme'].str.count(' ') + 1\n",
    "dfFixed['pWords'] = dfFixed['phoneme'].str.count(' ') + 1\n",
    "dfFixed['grapheme'] = dfFixed['grapheme'].str.split(' ')\n",
    "dfFixed['phoneme'] = dfFixed['phoneme'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed = (dfFixed.groupby('filename', as_index=False)\n",
    "    .apply(lambda x: x.reset_index(drop=True)).reset_index().drop('level_0', axis=1))\n",
    "dfFixed.level_1 = dfFixed.level_1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfFixed[dfFixed.gWords > dfFixed.pWords].apply(lambda x:\n",
    "    x.phoneme.extend([''] * (x.gWords - x.pWords)), axis=1)\n",
    "dfFixed[dfFixed.pWords > dfFixed.gWords].apply(lambda x:\n",
    "    x.grapheme.extend([''] * (x.pWords - x.gWords)), axis=1)\n",
    "dfFixedWords = (dfFixed.apply(pd.Series.explode)\n",
    "    .drop(['lang', 'gWords', 'pWords'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonemes = dfWords['phoneme']\n",
    "phonemesFixed = dfFixedWords['phoneme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon = dfWords[phonemesFixed != phonemes][['filename', 'level_1', 'grapheme', 'phoneme']].to_csv('phon.txt', index=False)\n",
    "phonFixed = dfFixedWords[phonemes != phonemesFixed][['filename', 'level_1', 'grapheme', 'phoneme']].to_csv('phonFixed.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon.to_csv('phon.txt', index=False)\n",
    "phonFixed.to_csv('phonFixed.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(target, predicted):\n",
    "    d = np.zeros((len(target) + 1) * (len(predicted) + 1), dtype=np.uint8)\n",
    "    d = d.reshape((len(target) + 1, len(predicted) + 1))\n",
    "    for i in range(len(target) + 1):\n",
    "        for j in range(len(predicted) + 1):\n",
    "            if i == 0:\n",
    "                d[0][j] = j\n",
    "            elif j == 0:\n",
    "                d[i][0] = i\n",
    "\n",
    "    for i in range(1, len(target) + 1):\n",
    "        for j in range(1, len(predicted) + 1):\n",
    "            if target[i - 1] == predicted[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1][j - 1] + 1\n",
    "                insertion = d[i][j - 1] + 1\n",
    "                deletion = d[i - 1][j] + 1\n",
    "                d[i][j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    return d[len(target)][len(predicted)], len(target)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cde60fc070cc7e7c1fe92306444b0b222b6cd64a006490f96de528ff53cd4f57"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
